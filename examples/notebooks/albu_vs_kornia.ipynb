{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T12:59:06.804165Z",
     "start_time": "2020-07-28T12:59:04.961466Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yauheni-kachan/miniconda3/envs/catalyst/lib/python3.8/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable, Dict, Optional\n",
    "import functools\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "from catalyst import utils\n",
    "from catalyst.contrib.data.cv import ImageReader\n",
    "from catalyst.data import PathsDataset, ScalarReader, ReaderCompose\n",
    "\n",
    "\n",
    "# def get_label_fn(fn: str) -> str:\n",
    "#     return Path(fn).parent.name\n",
    "#\n",
    "#\n",
    "# def get_class_fn(fn: str, label2class: Dict[str, int]) -> int:\n",
    "#     return label2class[get_label_fn(fn)]\n",
    "#\n",
    "#\n",
    "class ImageFolderDataset(PathsDataset):\n",
    "    def __init__(\n",
    "        self, rootpath: str, transform: Optional[Callable[[Dict], Dict]] = None\n",
    "    ) -> None:\n",
    "        files = glob.iglob(f\"{rootpath}/**/*\", recursive=False)  # TODO: set to `true`?\n",
    "        images = sorted(filter(utils.has_image_extension, files))\n",
    "\n",
    "        labels = sorted({Path(f).parent.name for f in images})\n",
    "        label2class = {label: index for index, label in enumerate(labels)}\n",
    "\n",
    "        super().__init__(\n",
    "            filenames=images,\n",
    "            open_fn=ReaderCompose([\n",
    "                ImageReader(input_key=\"image\", rootpath=rootpath),\n",
    "                ScalarReader(\n",
    "                    input_key=\"targets\",  # TODO: add `target_key`\n",
    "                    output_key=\"targets\",\n",
    "                    dtype=int,\n",
    "                    default_value=-1,\n",
    "                ),\n",
    "            ]),\n",
    "            label_fn=lambda fn: label2class[Path(fn).parent.name],  # TODO: replace lambda with func\n",
    "            # label_fn=functools.partial(get_class_fn, label2class=label2class),\n",
    "            features_key=\"image\",\n",
    "            dict_transform=transform,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T12:59:07.017840Z",
     "start_time": "2020-07-28T12:59:06.805702Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import collections\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "\n",
    "bs = 3\n",
    "num_workers = 0\n",
    "\n",
    "image_size = 160\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.LongestMaxSize(max_size=image_size),\n",
    "    A.PadIfNeeded(\n",
    "        min_height=image_size,\n",
    "        min_width=image_size,\n",
    "        border_mode=cv2.BORDER_CONSTANT,\n",
    "        value=255,  # pad with white as in original dataset\n",
    "    ),\n",
    "    A.Normalize(),\n",
    "    A.pytorch.ToTensor(),\n",
    "])\n",
    "\n",
    "def data_transfrom(dict_: Dict) -> Dict:\n",
    "    return transform(**dict_)\n",
    "\n",
    "\n",
    "loaders = collections.OrderedDict()\n",
    "\n",
    "trainset = ImageFolderDataset(rootpath=f'data/imagenette2-{image_size}/train/', transform=data_transfrom)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "testset = ImageFolderDataset(rootpath=f'data/imagenette2-{image_size}/val/', transform=data_transfrom)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=bs, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "loaders[\"train\"] = trainloader\n",
    "loaders[\"valid\"] = testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T12:59:08.072387Z",
     "start_time": "2020-07-28T12:59:07.019418Z"
    }
   },
   "outputs": [],
   "source": [
    "import pretrainedmodels\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "def get_model(model_name: str, num_classes: int, pretrained: str = \"imagenet\"):\n",
    "    model_fn = pretrainedmodels.__dict__[model_name]\n",
    "    model = model_fn(num_classes=1000, pretrained=pretrained)\n",
    "    \n",
    "    model.fc = nn.Sequential()\n",
    "    dim_feats = model.last_linear.in_features\n",
    "    model.last_linear = nn.Linear(dim_feats, num_classes)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model(model_name=\"resnet18\", num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-28T13:28:58.874730Z",
     "start_time": "2020-07-28T12:59:08.074224Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 * Epoch (train): 100% 3157/3157 [22:48<00:00,  2.31it/s, loss=1.898]\n",
      "1/3 * Epoch (valid): 100% 1309/1309 [01:18<00:00, 16.64it/s, loss=10.976]   \n",
      "[2020-07-28 16:23:15,104] \n",
      "1/3 * Epoch 1 (_base): lr=0.0010 | momentum=0.9000\n",
      "1/3 * Epoch 1 (train): loss=1.8749\n",
      "1/3 * Epoch 1 (valid): loss=2.4104\n",
      "Early exiting                                                          \n",
      "2/3 * Epoch (train):  25% 792/3157 [05:43<17:58,  2.19it/s, loss=3.044]"
     ]
    }
   ],
   "source": [
    "from catalyst.dl.runner import SupervisedRunner\n",
    "\n",
    "# experiment setup\n",
    "num_epochs = 3\n",
    "logdir = \"./logs/cifar_simple_notebook_1\"\n",
    "\n",
    "# model, criterion, optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# model runner\n",
    "runner = SupervisedRunner(input_key='image')\n",
    "\n",
    "# model training\n",
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    loaders=loaders,\n",
    "    logdir=logdir,\n",
    "    num_epochs=num_epochs,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
